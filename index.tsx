
import { GoogleGenAI, Modality, Type, FunctionDeclaration, LiveServerMessage } from "@google/genai";

// æ¸¸æˆæ•°æ®
const GESTURES = [
    { emoji: 'âœŒï¸', name: 'å‰ªåˆ€æ‰‹', desc: 'ä¼¸å‡ºé£ŸæŒ‡å’Œä¸­æŒ‡' },
    { emoji: 'ğŸ‘', name: 'ç‚¹èµ', desc: 'ç«–èµ·å¤§æ‹‡æŒ‡' },
    { emoji: 'ğŸ‘Œ', name: 'OK', desc: 'é£ŸæŒ‡å’Œå¤§æ‹‡æŒ‡æˆåœˆ' },
    { emoji: 'ğŸ–ï¸', name: 'å‡»æŒ', desc: 'å¼ å¼€äº”æŒ‡' },
    { emoji: 'ğŸ«¶', name: 'æ¯”å¿ƒ', desc: 'åŒæ‰‹æˆ–å•æ‰‹ç»„æˆçˆ±å¿ƒ' },
    { emoji: 'âœŠ', name: 'åŠ æ²¹', desc: 'æ¡ç´§æ‹³å¤´' }
];

// çŠ¶æ€å˜é‡
let currentGestureIndex = 0;
let score = 0;
let session: any = null;
let audioContext: AudioContext | null = null;
let outputAudioContext: AudioContext | null = null;
let nextStartTime = 0;
const sources = new Set<AudioBufferSourceNode>();
let frameInterval: any = null;

// è·å– DOM å…ƒç´  (ç”±äºæ˜¯ ES æ¨¡å—ï¼Œä¼šåœ¨ HTML è§£æåæ‰§è¡Œ)
const getEl = (id: string) => document.getElementById(id) as HTMLElement;

const bgVideo = document.getElementById('bgVideo') as HTMLVideoElement;
const viewIdle = getEl('view-idle');
const viewConnecting = getEl('view-connecting');
const viewPlaying = getEl('view-playing');
const viewFinished = getEl('view-finished');
const scoreContainer = getEl('scoreContainer');
const scoreValue = getEl('scoreValue');
const gestureEmoji = getEl('gestureEmoji');
const gestureName = getEl('gestureName');
const gestureDesc = getEl('gestureDesc');
const progressBar = getEl('progressBar');
const aiTranscription = getEl('aiTranscription');
const startBtn = getEl('startBtn');

// éŸ³é¢‘è¾…åŠ©å‡½æ•°
// Manually implement encode function as per Google GenAI SDK guidelines
function encode(bytes: Uint8Array): string {
    let binary = '';
    for (let i = 0; i < bytes.byteLength; i++) binary += String.fromCharCode(bytes[i]);
    return btoa(binary);
}

// Manually implement decode function as per Google GenAI SDK guidelines
function decode(base64: string): Uint8Array {
    const binary = atob(base64);
    const bytes = new Uint8Array(binary.length);
    for (let i = 0; i < binary.length; i++) bytes[i] = binary.charCodeAt(i);
    return bytes;
}

// Manually implement audio decoding for raw PCM data from Live API
async function decodeAudioData(data: Uint8Array, ctx: AudioContext, sampleRate: number, numChannels: number): Promise<AudioBuffer> {
    const dataInt16 = new Int16Array(data.buffer);
    const frameCount = dataInt16.length / numChannels;
    const buffer = ctx.createBuffer(numChannels, frameCount, sampleRate);
    for (let channel = 0; channel < numChannels; channel++) {
        const channelData = buffer.getChannelData(channel);
        for (let i = 0; i < frameCount; i++) {
            channelData[i] = dataInt16[i * numChannels + channel] / 32768.0;
        }
    }
    return buffer;
}

// æ¸¸æˆé€»è¾‘å‡½æ•°
function updateUI() {
    const g = GESTURES[currentGestureIndex];
    gestureEmoji.innerText = g.emoji;
    gestureName.innerText = g.name;
    gestureDesc.innerText = g.desc;
    scoreValue.innerText = score.toString();
    progressBar.style.width = `${((currentGestureIndex + 1) / GESTURES.length) * 100}%`;
}

function nextStep() {
    if (currentGestureIndex < GESTURES.length - 1) {
        currentGestureIndex++;
        updateUI();
    } else {
        finishGame();
    }
}

function finishGame() {
    if (frameInterval) clearInterval(frameInterval);
    if (session) session.close();
    viewPlaying.classList.add('hidden');
    viewFinished.classList.remove('hidden');
    getEl('finalScore').innerText = score.toString();
    bgVideo.style.opacity = "0.2";
}

// æ ¸å¿ƒæŒ‘æˆ˜é€»è¾‘
async function startChallenge() {
    try {
        viewIdle.classList.add('hidden');
        viewConnecting.classList.remove('hidden');

        const stream = await navigator.mediaDevices.getUserMedia({ audio: true, video: { facingMode: 'user' } });
        bgVideo.srcObject = stream;
        bgVideo.style.opacity = "0.8";

        audioContext = new (window.AudioContext || (window as any).webkitAudioContext)({ sampleRate: 16000 });
        outputAudioContext = new (window.AudioContext || (window as any).webkitAudioContext)({ sampleRate: 24000 });

        // Initialize GoogleGenAI with API key from environment
        const ai = new GoogleGenAI({ apiKey: process.env.API_KEY });
        
        // Define function declaration using proper Type enum values to fix Type mismatch error
        const updateTool: FunctionDeclaration = {
            name: 'update_game_progress',
            parameters: {
                type: Type.OBJECT,
                description: 'å½“ç”¨æˆ·æˆåŠŸåšå‡ºæŒ‡å®šæ‰‹åŠ¿æ—¶è°ƒç”¨æ­¤å‡½æ•°ã€‚',
                properties: {
                    success: { type: Type.BOOLEAN, description: 'æ˜¯å¦æˆåŠŸåšå‡ºæ‰‹åŠ¿' },
                    pointsAwarded: { type: Type.NUMBER, description: 'å¥–åŠ±çš„åˆ†æ•°' }
                },
                required: ['success', 'pointsAwarded']
            }
        };

        const sessionPromise = ai.live.connect({
            model: 'gemini-2.5-flash-native-audio-preview-12-2025',
            callbacks: {
                onopen: () => {
                    viewConnecting.classList.add('hidden');
                    viewPlaying.classList.remove('hidden');
                    scoreContainer.classList.remove('hidden');
                    updateUI();

                    const source = audioContext!.createMediaStreamSource(stream);
                    const processor = audioContext!.createScriptProcessor(4096, 1, 1);
                    processor.onaudioprocess = (e) => {
                        const input = e.inputBuffer.getChannelData(0);
                        const int16 = new Int16Array(input.length);
                        for (let i = 0; i < input.length; i++) int16[i] = input[i] * 32768;
                        // Use sessionPromise to ensure connection is established before sending data
                        sessionPromise.then(s => s.sendRealtimeInput({
                            media: { data: encode(new Uint8Array(int16.buffer)), mimeType: 'audio/pcm;rate=16000' }
                        }));
                    };
                    source.connect(processor);
                    processor.connect(audioContext!.destination);

                    const canvas = document.getElementById('frameCanvas') as HTMLCanvasElement;
                    const ctx = canvas.getContext('2d')!;
                    frameInterval = setInterval(() => {
                        ctx.drawImage(bgVideo, 0, 0, canvas.width, canvas.height);
                        canvas.toBlob(blob => {
                            if (!blob) return;
                            const reader = new FileReader();
                            reader.onloadend = () => {
                                const base64 = (reader.result as string).split(',')[1];
                                sessionPromise.then(s => s.sendRealtimeInput({
                                    media: { data: base64, mimeType: 'image/jpeg' }
                                }));
                            };
                            reader.readAsDataURL(blob);
                        }, 'image/jpeg', 0.6);
                    }, 500);
                },
                onmessage: async (msg: LiveServerMessage) => {
                    // Extract audio from server response
                    const audioBase64 = msg.serverContent?.modelTurn?.parts?.[0]?.inlineData?.data;
                    if (audioBase64 && outputAudioContext) {
                        nextStartTime = Math.max(nextStartTime, outputAudioContext.currentTime);
                        const buffer = await decodeAudioData(decode(audioBase64), outputAudioContext, 24000, 1);
                        const source = outputAudioContext.createBufferSource();
                        source.buffer = buffer;
                        source.connect(outputAudioContext.destination);
                        // Schedule playback using nextStartTime to ensure gapless audio
                        source.start(nextStartTime);
                        nextStartTime += buffer.duration;
                        sources.add(source);
                    }

                    // Handle transcriptions
                    if (msg.serverContent?.outputTranscription) {
                        aiTranscription.innerText = msg.serverContent.outputTranscription.text;
                    }

                    // Handle tool calls from the model
                    if (msg.toolCall) {
                        for (const fc of msg.toolCall.functionCalls) {
                            if (fc.name === 'update_game_progress') {
                                score += (fc.args as any).pointsAwarded;
                                nextStep();
                                // Send tool response back to model, functionResponses is an object in Live API
                                sessionPromise.then(s => s.sendToolResponse({
                                    functionResponses: { id: fc.id, name: fc.name, response: { result: "ok, score updated" } }
                                }));
                            }
                        }
                    }

                    // Handle interruptions by stopping all playing audio nodes
                    if (msg.serverContent?.interrupted) {
                        sources.forEach(s => { try { s.stop(); } catch(e) {} });
                        sources.clear();
                        nextStartTime = 0;
                    }
                }
            },
            config: {
                responseModalities: [Modality.AUDIO],
                outputAudioTranscription: {},
                tools: [{ functionDeclarations: [updateTool] }],
                systemInstruction: `
                    ä½ æ˜¯ä¸€ä¸ªç–¯ç‹‚çš„æ‰‹åŠ¿æŒ‘æˆ˜èµ›ä¸»æŒäººã€‚ä½ çš„åå­—å«â€œçµåŠ¨å°Gâ€ã€‚
                    å½“å‰æ¸¸æˆæ‰‹åŠ¿åˆ—è¡¨ï¼š${GESTURES.map(g => g.name).join(', ')}ã€‚
                    ä½ çš„ä»»åŠ¡ï¼š
                    1. å®æ—¶è§‚çœ‹è§†é¢‘ï¼Œå¼•å¯¼ç”¨æˆ·ä¸€ä¸ªæ¥ä¸€ä¸ªåœ°å®Œæˆæ‰‹åŠ¿ã€‚
                    2. è¯­æ°”å¿…é¡»æå…¶äº¢å¥‹ã€å¹½é»˜ã€åƒç”µè§†ç»¼è‰ºä¸»æŒäººã€‚
                    3. å½“ä½ çœ‹åˆ°ç”¨æˆ·æˆåŠŸåšå‡ºå½“å‰æ‰‹åŠ¿ï¼ˆç›®å‰éœ€è¦å®Œæˆçš„æ˜¯ï¼š${GESTURES[currentGestureIndex]?.name}ï¼‰æ—¶ï¼Œ
                       å¿…é¡»ç«‹åˆ»è°ƒç”¨ update_game_progress å‡½æ•°æ¥ç»™ç”¨æˆ·åŠ åˆ†ï¼Œå¹¶å…´å¥‹åœ°å®£å¸ƒä¸‹ä¸€ä¸ªæŒ‘æˆ˜ã€‚
                    4. æ¯æ¬¡æˆåŠŸåŠ  100 åˆ†ã€‚
                    5. åªèƒ½ä½¿ç”¨ä¸­æ–‡ã€‚
                `
            }
        });
        session = await sessionPromise;

    } catch (err) {
        console.error(err);
        alert('æ— æ³•å¯åŠ¨æŒ‘æˆ˜ï¼Œè¯·ç¡®ä¿å·²æˆäºˆæ‘„åƒå¤´å’Œéº¦å…‹é£æƒé™ã€‚');
    }
}

// ç»‘å®šäº‹ä»¶
if (startBtn) {
    startBtn.addEventListener('click', startChallenge);
}
